## 색인 과정 이해하기

### 색인(indexing)이란

- 문서를 분석하고 저장하는 과정

### 색인 과정

```
인덱스가 있는지 확인 -> 매핑이 있는지 확인 -> 매핑 정보 올바르지 않다면 색인 불가
매핑이 올바르다면 -> inrerted index 생성 -> 프라이머리 샤드에 저장 -> 레플리카 샤드에 복사
```

### 데이터 노드가 3개이고 프라이머리 샤드가 1개인 경우

<img width="932" alt="image" src="https://github.com/mimseong/Study/assets/50068946/6ebcb875-7e90-4d96-a65a-170e025c26df">

```
number_of_shards: 1
number_of_replicas: 1
```

**프라이머리 샤드가 있는 데이터 노드로 요청이 온다면**

- 0번 프라이머리 샤드에 데이터 저장
- 이후 0번 레플리카 샤드로 복사

**프라이머리 샤드가 없는 데이터 노드로 요청이 온다면**

- 프라이머리 샤드가 있는 데이터 노드로 이동
- 0번 프라이머리 샤드에 데이터 저장
- 0번 레플리카 샤드로 데이터 복사

**이 구조의 문제점**

- 아무것도 안 하는 데이터 노드가 있다
- 클러스터의 이점을 살리지 못하는 구조
- 프라이머리 샤드가 1개이기 때문에 색인 과정이 하나의 데이터 노드에서만 이루어진다
- 색인 과정은 CPU를 많이 쓰는 작업이다
- 샤드 개수를 적절히 정하는게 성능에 큰 영향을 미친다

### 데이터 노드가 3개이고 프라이머리 샤드가 3개인 경우

<img width="831" alt="image" src="https://github.com/mimseong/Study/assets/50068946/a0e42d97-52e7-4d44-bd78-08b5d830fb6b">


- 샤드가 적절히 분배되어 있다

### 데이터 노드가 4개이고 프라이머리 샤드가 3개인 경우

<img width="919" alt="image" src="https://github.com/mimseong/Study/assets/50068946/b5b20e19-2140-4cdb-b241-64676da2be53">


- 샤드의 용량이 10G라고 가정할 경우 데이터 노드의 용량 불균형이 발생할 수 있다

### 적절한 샤드의 개수는?

- 처음부터 완벽한 샤드 배치 계획을 세울 수는 없다
- 배치 계획을 세우고 테스트를 해보면서 결정할 수 밖에 없음
- CPU 5%만 쓰고 있다면 프라이머리 샤드의 개수를 늘린다던가

```
하루 100GB 로그 30일동안 저장한다면
100GB * 2 (레플리카) * 30 = 6000GB
인덱스별 샤드 최대 크기를 10GB로 설정하면 인덱스 별 프라이머리 샤드 개수는 10개
데이터 노드의 개수를 10개로 설정한다면 데이터 노드 당 가져야 할 디스크 크기 600GB
데이터 노드의 장애를 대비해서 700GB 정도 설정
```

## 검색 과정 이해하기

### 검색 과정

```
검색어 분석 -> inverted index 검색 -> 검색 결과 표시
```

- 애널라이저로 토큰을 만들고
- 생성된 토큰을 inverted index로 검색해서
- 검색 결과를 보여준다

### inverted index

- 문자열을 분석한 결과를 저장하고 있는 구조체

<img width="204" alt="image" src="https://github.com/mimseong/Study/assets/50068946/3f9493d7-e5b3-4f7a-a7f3-f52939be6feb">

### 애널라이저

- 문자열을 분석해서 토큰을 만들어 내는 과정

```
문자열 -> character filter(특수 문자 제거) -> tokenizer(공백 기준 자름) -> token fillter(소문자로 만듬) -> tokens
```

```
GET /analyze
{
	analyzer: standard,
	text: "linux kernal"
}
```

- analyzer: 어떤 애널라이저를 사용할 것인지
- text: 무엇을 분석할 것인지
- 위 요청으로 문장이 애널라이저를 통과하면 어떻게 될 것인지 확인할 수 있다

### 검색 성능을 높이는 방법

- 검색 요청은 프라이머리 샤드와 레플리카 샤드 모두가 처리할 수 있다
- (색인은 프라이머리 샤드가 가능하다)
- 만약 색인은 이미 충분하고 검색 성능을 높이고 싶다면?
- 레플리카 샤드 개수를 늘리면 된다
- 레플리카 샤드 개수를 늘리고 나서 데이터 노드 수를 늘리자
- (데이터 노드를 늘린다고 검색 성능이 높아지지 않는다)

## text vs keyword

text와 keyword 타입: 둘 다 문자열을 나타내기 위한 타입

- text: 전문 검색을 위해 토큰 생성
- keyword: Exact Matching을 위해 토큰 생성

### 애널라이저로 차이를 확인해보자

```
GET /analyze
{
	analyzer: standard,
	text: "I am mimseong"
}
```

- I, am, mimseong 토큰 생성
- mimseong, am 검색 가능

```
GET /analyze
{
	analyzer: keyword,
	text: "I am mimseong"
}
```

- "I am mimseong"이 토큰
- "I am mimseong"으로만 검색 가능
- 그대로 저장하기 때문에 keyword 타입이 색인 속도가 빠르다

### 문자열 타입을 동적 매핑하는 경우

- 문자열 필드가 동적 매핑되면 text와 keyword 타입 모두 생성한다
- 동적 매핑으로 keyword를 생성할 경우 ignore_above: 256으로 설정
- 256 길이 이상의 문자열은 색인을 하지 않아 검색이나 집계 불가능

**example**

- author이라는 필드는 문자열이다

```
author
author.keyword
```

- 하나의 문자열에 두 개의 필드가 만들어진다
- 문자열 특성에 따라 text, keyword를 정적 매핑해주면 성능에 도움이 된다

### text, keyword 타입으로 되면 좋을 필드

**text**

- 주소, 이름, 물품 상세 정보
- 문자열 중간 단어를 검색할 경우
- url

**keyword**

- 성별, 물품 카테고리
- http method
- 쪼개기 어려운 것들

